{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 01. Dicionário de modelos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 01.1. Modelos dummy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 01.1.1. Modelo dummy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"../images/illustrations/models/dummy.png\" alt=\"Dummy\" width=\"400\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **Definição:** O modelo Dummy faz previsões simples e não baseadas em dados, servindo como um baseline para comparações. Ele pode prever valores constantes, aleatórios ou usar estratégias simples como a classe mais frequente em classificações ou a média em regressões\n",
    "- **Funcionamento:** O modelo Dummy faz previsões com base em regras triviais definidas pelo usuário, como sempre prever a classe majoritária, valores médios ou aleatórios. Para classificação, pode usar a estratégia \"most frequent\" (classe mais frequente), \"stratified\" (aleatoriedade proporcional às classes) ou \"uniform\" (aleatoriedade igual entre classes). Para regressão, pode usar estratégias como a média ou mediana dos valores no treinamento\n",
    "- **Indicações:** É utilizado para criar uma linha de base mínima para comparar o desempenho de modelos mais avançados. Útil para verificar se um modelo real está superando previsões triviais ou aleatórias\n",
    "- **Restrições:** Não tem nenhuma capacidade de aprendizado real e não captura padrões dos dados. Apenas serve como benchmark básico, sendo inútil para prever de maneira eficaz dados complexos ou cenários onde há padrões significativos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 01.2. Modelos de classificação"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 01.2.1. Árvore de classificação"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"../images/illustrations/models/classification_tree.png\" alt=\"Classification_Tree\" width=\"400\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **Definição:** Estrutura hierárquica que divide dados em grupos (nós) com base em características\n",
    "- **Funcionamento:** O algoritmo começa com o conjunto de dados completo como a raiz da árvore. Em cada nó, ele seleciona a característica que melhor divide os dados em grupos homogêneos em relação à variável de saída (classe). A qualidade da divisão é medida usando métricas como entropia ou índice de Gini. A divisão continua até que uma condição de parada seja atendida, como atingir uma profundidade máxima, ter um número mínimo de amostras em um nó, ou todos os pontos no nó pertencerem à mesma classe. Cada folha da árvore representa uma classe final, e as previsões são feitas com base na classe que a maioria dos pontos nessa folha pertence. A árvore pode ser visualizada como uma série de perguntas sim/não, que segmentam os dados em grupos\n",
    "- **Indicações:** Ideal para problemas onde a interpretabilidade é crucial e para dados mistos (categóricos e contínuos)\n",
    "- **Restrições:** Pode ser muito sensível a pequenas variações nos dados, resultando em árvores diferentes (overfitting). Além disso, árvores muito profundas podem ser complexas e difíceis de interpretar"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 01.2.2. Regressão logística"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"../images/illustrations/models/logistic_regression.png\" alt=\"Logistic_Regression\" width=\"400\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **Definição:** Modelo estatístico que usa uma função logística para prever a probabilidade de um evento\n",
    "- **Funcionamento:** A regressão logística utiliza a função logística (ou sigmoide) para modelar a relação entre uma variável dependente binária e uma ou mais variáveis independentes. A função logística transforma a saída linear em uma probabilidade que varia entre 0 e 1. O modelo é ajustado usando a máxima verossimilhança, que procura os parâmetros (coeficientes) que maximizam a probabilidade de observar os dados dados os parâmetros do modelo. Após o ajuste, a classificação é feita atribuindo a classe 1 se a probabilidade prevista for maior que 0,5 (ou outro limiar definido)\n",
    "- **Indicações:** Funciona bem quando as classes são separáveis linearmente e fornece probabilidades interpretáveis para cada classe\n",
    "- **Restrições:** Assume que a relação entre as variáveis independentes e a probabilidade é linear; pode falhar em capturar interações complexas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 01.2.3. Naive Bayes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"../images/illustrations/models/naive_bayes.png\" alt=\"Naive_Bayes\" width=\"400\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **Definição:** Algoritmo baseado no teorema de Bayes, que assume independência entre as características\n",
    "- **Funcionamento:** O \"naive\" refere-se à suposição de que as características são independentes entre si. Para classificar, o algoritmo calcula P(C∣X) para cada classe e escolhe a classe com a maior probabilidade. O algoritmo pode ser implementado com diferentes distribuições (gaussiana para contínuos, multinomial para texto, etc.)\n",
    "- **Indicações:** Rápido e eficiente em grandes conjuntos de dados, funciona bem em textos e dados de alta dimensionalidade\n",
    "- **Restrições:** A suposição de independência é frequentemente irrealista; pode resultar em desempenho inferior se as características forem fortemente correlacionadas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 01.2.4. KNN - K-Nearest Neighbors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"../images/illustrations/models/knn.png\" alt=\"KNN\" width=\"400\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **Definição:** Classifica novos pontos com base na maioria das classes dos k vizinhos mais próximos\n",
    "- **Funcionamento:** O algoritmo KNN não constrói um modelo explícito, mas armazena o conjunto de dados completo. Para classificar um novo ponto, ele calcula a distância (geralmente Euclidiana) entre o ponto e todos os outros pontos do conjunto de treinamento. O número k de vizinhos mais próximos é escolhido. O algoritmo determina a classe do novo ponto com base na classe mais comum entre os k vizinhos mais próximos. A escolha de k é crucial: um k muito pequeno pode ser sensível a outliers, enquanto um k muito grande pode suavizar demais a decisão. O KNN pode ser adaptado para regressão, onde a média (ou outra função de agregação) dos valores dos vizinhos é calculada\n",
    "- **Indicações:** Simples de implementar e eficaz em problemas de classificação com classes bem definidas\n",
    "- **Restrições:** Desempenho pode ser afetado por dados desbalanceados e a necessidade de escalar os dados; lento em grandes conjuntos de dados devido à necessidade de calcular distâncias"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 01.2.5. SVM - Support Vector Machine"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"../images/illustrations/models/svm.png\" alt=\"SVM\" width=\"400\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **Definição:** Método que encontra um hiperplano que separa diferentes classes com a maior margem\n",
    "- **Funcionamento:** O SVM procura encontrar um hiperplano que separa diferentes classes com a maior margem. A margem é definida como a distância entre o hiperplano e os pontos de dados mais próximos de qualquer classe (os vetores de suporte). O modelo é ajustado resolvendo um problema de otimização que maximiza essa margem, e pode ser estendido para problemas não linearmente separáveis usando kernels (como o kernel radial, polinomial, etc.) para transformar os dados em um espaço de alta dimensão onde eles se tornam separáveis. A formulação matemática envolve encontrar os parâmetros do hiperplano que minimizam um termo de erro e maximizam a margem\n",
    "- **Indicações:** Eficaz em dados de alta dimensão e quando há uma clara margem de separação entre classes\n",
    "- **Restrições:** Pode ser sensível a outliers e exige um tempo de computação maior, especialmente para grandes conjuntos de dados. A escolha do kernel e dos parâmetros pode ser complexa"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 01.3. Modelos de regressão"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 01.3.1. Linear Regression (Regressão Linear)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"../images/illustrations/models/linear_regression.png\" alt=\"Linear_Regression\" width=\"400\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **Definição:** A regressão linear é um modelo de aprendizado supervisionado usado para prever um valor contínuo com base em uma ou mais variáveis independentes, assumindo que há uma relação linear entre essas variáveis e a variável de saída\n",
    "- **Funcionamento:** O objetivo do modelo é encontrar os valores dos coeficientes que minimizam a soma dos erros quadráticos (SSE) entre os valores previstos e os valores reais. A minimização é feita usando o método dos Mínimos Quadrados Ordinários (OLS). Esse método calcula os coeficientes de tal forma que o erro quadrático médio (MSE) seja minimizado\n",
    "- **Indicações:** Adequado quando a relação entre as variáveis dependente e independentes é linear. Útil em problemas simples, interpretáveis, e quando o foco está em inferir a importância das variáveis\n",
    "- **Restrições:** Assume uma relação linear entre as variáveis, o que pode não ser verdadeiro em muitos cenários. Sensível a outliers, que podem distorcer a linha de regressão. Não lida bem com multicolinearidade (correlação entre variáveis independentes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 01.3.2. Polynomial Regression - (Regressão Polinomial)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"../images/illustrations/models/polynomial_regression.png\" alt=\"Polynomial_Regression\" width=\"400\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **Definição:** A regressão polinomial é uma extensão da regressão linear que permite capturar relações não lineares entre as variáveis independentes e a variável dependente, ao introduzir termos polinomiais\n",
    "- **Funcionamento:** O modelo ajusta uma curva polinomial aos dados, utilizando o método dos mínimos quadrados para estimar os coeficientes. O grau do polinômio n deve ser escolhido com cuidado: polinômios de grau baixo podem não capturar a complexidade dos dados, enquanto graus muito altos podem resultar em overfitting\n",
    "- **Indicações:** Adequado para modelar dados onde há uma relação não linear entre as variáveis. Útil quando há tendências curvas ou comportamentos complexos\n",
    "- **Restrições:** Propenso ao overfitting, especialmente com polinômios de alta ordem. A escolha do grau do polinômio é crucial e pode ser difícil. Pode ser instável fora do intervalo de observação dos dados (extrapolação)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 01.3.3. Regression Tree (Árvore de Regressão)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"../images/illustrations/models/regression_tree.png\" alt=\"Regression_Tree\" width=\"400\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **Definição:** Uma árvore de regressão é um modelo de árvore de decisão usado para prever valores contínuos, dividindo repetidamente os dados em subconjuntos com base em uma característica que minimiza o erro dentro de cada divisão\n",
    "- **Funcionamento:** O algoritmo divide os dados em subconjuntos baseados na característica que resulta na maior redução de variância ou erro quadrático médio (MSE). A árvore começa com todos os dados na raiz e divide os nós sucessivamente até que uma condição de parada seja atendida (como uma profundidade máxima ou número mínimo de pontos em uma folha). Cada folha da árvore contém um valor predito que é a média dos valores de todas as amostras presentes naquela folha\n",
    "- **Indicações:** Funciona bem com dados não lineares. Capaz de capturar interações entre características e produzir previsões intuitivas\n",
    "- **Restrições:** Propensa ao overfitting se não podada ou se a profundidade da árvore for muito grande. As previsões podem ser \"em degraus\" e não suaves, já que os valores são previsões médias em grupos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 01.3.4. KNR - K-Nearest Neighbor Regressor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"../images/illustrations/models/knr.png\" alt=\"KNR\" width=\"400\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **Definição:** O KNN é um algoritmo de aprendizado supervisionado que faz previsões com base nos k vizinhos mais próximos de um ponto, calculando a média dos valores desses vizinhos para prever um valor contínuo\n",
    "- **Funcionamento:** Para um novo ponto, o KNN calcula a distância entre esse ponto e todos os outros pontos do conjunto de treinamento, usando geralmente a distância Euclidiana. Os k pontos mais próximos são selecionados, e a previsão é a média dos valores desses k pontos. A escolha de k é importante: valores pequenos de k podem ser sensíveis ao ruído, enquanto valores grandes podem suavizar demais as previsões\n",
    "- **Indicações:** Funciona bem em casos onde há uma relação local clara entre variáveis. Útil em problemas com padrões complexos e não lineares\n",
    "- **Restrições:** Pode ser computacionalmente caro em grandes conjuntos de dados, pois requer o cálculo da distância para cada ponto. Sensível à escolha do valor de k e à escala das variáveis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 01.3.5. Random Forest Regressor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"../images/illustrations/models/random_forest_regressor.png\" alt=\"Random_Forest_Regressor\" width=\"400\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **Definição:** O Random Forest é um modelo de ensemble que combina várias árvores de decisão (normalmente com amostragem bootstrap) para melhorar a precisão e reduzir o overfitting, prevendo valores contínuos a partir de múltiplas árvores\n",
    "- **Funcionamento:** O algoritmo cria várias árvores de decisão independentes. Cada árvore é treinada em um subconjunto aleatório dos dados (amostragem bootstrap) e em uma amostra aleatória de características. Para fazer uma previsão, o Random Forest combina as previsões de todas as árvores individuais (geralmente por média). Este processo reduz a variância do modelo final, resultando em previsões mais estáveis e precisas\n",
    "- **Indicações:** Eficaz em dados com muitas variáveis e interações complexas. Funciona bem mesmo quando há dados faltantes ou ruidosos\n",
    "- **Restrições:** Menos interpretável do que uma única árvore de decisão. Pode ser computacionalmente intensivo devido ao número de árvores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 01.3.6. XGBoost Regressor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"../images/illustrations/models/xgboost_regressor.png\" alt=\"XGBoost_Regressor\" width=\"400\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **Definição:** XGBoost é um algoritmo de boosting que cria um conjunto de árvores de decisão, onde cada nova árvore tenta corrigir os erros das anteriores, resultando em um modelo altamente preciso\n",
    "- **Funcionamento:** O XGBoost é uma forma avançada de \"gradient boosting\", onde novas árvores são adicionadas iterativamente para melhorar as previsões, corrigindo erros residuais das árvores anteriores. A função de custo é minimizada utilizando técnicas de descida de gradiente. XGBoost também inclui regularização (L1 e L2) para evitar overfitting e otimizações para tornar o treinamento eficiente\n",
    "- **Indicações:** Altamente eficaz em competições de machine learning e problemas complexos. Funciona bem com grandes conjuntos de dados e características heterogêneas\n",
    "- **Restrições:** Requer ajuste cuidadoso de hiperparâmetros. Menos interpretável do que modelos simples"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 01.4. Modelos de clusterização"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 01.4.1. K-Means"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"../images/illustrations/models/k_means.png\" alt=\"K_Means\" width=\"400\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **Definição:** O K-Means é um algoritmo de clusterização que particiona os dados em k clusters, tentando minimizar a soma das distâncias quadráticas entre os pontos e os centros dos clusters\n",
    "- **Funcionamento:** O algoritmo começa selecionando k centróides iniciais (pontos aleatórios). Em seguida, ele segue um processo iterativo de dois passos: Atribuição de Clusters: Cada ponto é atribuído ao centróide mais próximo, formando k clusters. Atualização dos Centróides: Os centróides são recalculados como a média dos pontos atribuídos a cada cluster. O processo se repete até que os centróides não mudem mais (convergência) ou um critério de parada seja atingido\n",
    "- **Indicações:** Funciona bem em dados esféricos e quando o número de clusters é conhecido. Simples e rápido para grandes conjuntos de dados\n",
    "- **Restrições:** Sensível a pontos de inicialização e ao número de clusters. Funciona mal quando os clusters têm formatos variados ou tamanhos diferentes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 01.4.2. Mean-Shift"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"../images/illustrations/models/mean_shift.png\" alt=\"Mean_Shift\" width=\"400\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **Definição:** Mean-Shift é um algoritmo de clusterização que tenta encontrar densidades máximas no espaço de características, movendo iterativamente os pontos em direção às regiões de maior densidade\n",
    "- **Funcionamento:** O algoritmo inicializa os pontos em um espaço de características e, em cada iteração, ajusta esses pontos movendo-os para a média dos pontos vizinhos, definidos por um raio de banda de largura (h).O processo continua até que todos os pontos tenham convergido para densidades máximas, formando clusters em torno desses picos\n",
    "- **Indicações:** Não requer especificar o número de clusters previamente. Funciona bem em dados de forma irregular\n",
    "- **Restrições:** Escolher a largura de banda h é crítico e pode ser difícil. O tempo de execução pode ser elevado, especialmente com grandes conjuntos de dados"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 01.4.3. DBSCAN (Density-Based Spatial Clustering of Applications with Noise)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"../images/illustrations/models/dbscan.png\" alt=\"Dbscan\" width=\"400\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **Definição:** DBSCAN é um algoritmo de clusterização baseado em densidade que forma clusters ao identificar regiões densamente conectadas no espaço de dados, separando ruído e outliers\n",
    "- **Funcionamento:** O DBSCAN começa selecionando um ponto aleatório. Se houver ao menos um número mínimo de pontos (minPts) em sua vizinhança (ϵ), o ponto é marcado como um \"núcleo\" e o processo continua expandindo o cluster ao redor desses pontos adjacentes. Pontos que não atendem ao critério de densidade mínima são rotulados como \"ruído\". Este processo resulta em clusters de formas arbitrárias baseados em densidade\n",
    "- **Indicações:** Funciona bem com clusters de forma irregular e tamanhos variados. Capaz de identificar e ignorar outliers\n",
    "- **Restrições:** Sensível à escolha dos parâmetros e minPts. Pode ser difícil de escalar para conjuntos de dados muito grandes"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
